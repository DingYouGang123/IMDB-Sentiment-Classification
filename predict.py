import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer, DebertaV2Tokenizer
import argparse

def load_model_and_tokenizer(model_path: str):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’ŒTokenizer"""
    # åˆ¤æ–­æ¨¡å‹ç±»å‹ï¼ŒåŠ è½½å¯¹åº”Tokenizer
    if "deberta" in model_path.lower():
        tokenizer = DebertaV2Tokenizer.from_pretrained(model_path)
    else:
        tokenizer = AutoTokenizer.from_pretrained(model_path)
    
    # å¤„ç†Pad Tokenç¼ºå¤±é—®é¢˜
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    # åŠ è½½æ¨¡å‹
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
    return model, tokenizer

def predict_sentiment(comment: str, model, tokenizer, max_length=512):
    """é¢„æµ‹å•æ¡è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘"""
    # åˆ†è¯
    inputs = tokenizer(
        comment,
        padding="max_length",
        truncation=True,
        max_length=max_length,
        return_tensors="pt"
    )
    
    # é¢„æµ‹
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        predicted_class_id = torch.argmax(logits, dim=1).item()
    
    # æ˜ å°„æ ‡ç­¾
    sentiment = "æ­£é¢" if predicted_class_id == 1 else "è´Ÿé¢"
    return sentiment

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="IMDBç”µå½±è¯„è®ºæƒ…æ„Ÿé¢„æµ‹å·¥å…·")
    parser.add_argument(
        "--model_path",
        type=str,
        required=True,
        help="è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„ï¼ˆå¦‚ï¼š./results/deberta-v3-baseï¼‰"
    )
    parser.add_argument(
        "--comment",
        type=str,
        required=True,
        help="å¾…é¢„æµ‹çš„ç”µå½±è¯„è®ºï¼ˆè‹±æ–‡ï¼‰"
    )
    
    args = parser.parse_args()
    
    # åŠ è½½æ¨¡å‹å’ŒTokenizer
    try:
        model, tokenizer = load_model_and_tokenizer(args.model_path)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
        return
    
    # é¢„æµ‹å¹¶è¾“å‡ºç»“æœ
    sentiment = predict_sentiment(args.comment, model, tokenizer)
    print(f"\nğŸ“ è¾“å…¥è¯„è®ºï¼š{args.comment}")
    print(f"â¤ï¸  é¢„æµ‹æƒ…æ„Ÿï¼š{sentiment}")

if __name__ == "__main__":
    main()